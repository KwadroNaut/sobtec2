
# Code is politiek, algoritmen zijn wapens van wiskundige vernietiging [^1]

***Benjamin Cadon***

![](../../bijdrage/gfx/illustraties/algoritmos-halfsize.png)

We horen er veel over, maar we zien ze nooit.
Wat zijn deze algoritmen?
Deze onzichtbare en prikkelende wezens die in onze gedachten glippen en bewonen
onze zakken.
Wat zijn hun bedoelingen?

Formeel gezien is een algoritme niets meer dan een niet-beledigende reeks van
verrichtingen die door gegevens worden gevoed om tot een resultaat te komen.
Toch automatiseren ze de oplossing van een reeks complexe problemen [^2] en dat is hoe sommigen van hen een hoog niveau van kunstmatige intelligentie te worden, dankzij bedrijven die ze vullen met gegevens, vriendelijk door ons gratis verstrekt.

## Een bestiarium [^3] van algoritmen

Er is geen vergelijking voor weten wat ze eten en identificeren en beter het begrijpen van hun rol in een samenleving van geïnformatiseerde mensen.
Zij waren niet geboren uit een elektrische vonk op de bodem van een zwavelhoudende zee van gegevens.
Hun stamouders zijn de mensen die de regels code schrijven die een programma dat een politiek en sociaal project in zich draagt dat wordt bepaald door een publieke of particuliere sponsor.

Algoritmen zijn nooit "neutraal" of onpartijdig.
Ze zijn gericht op het uitvoeren van de die aan hen zijn toegewezen, gewoonlijk door westerse mannetjes uit de hogere klassen, gekluisterd door het kapitalisme.

Het is ook belangrijk om te vermelden dat een dom algoritme gevoed met veel goede gegevens zullen meer succes hebben dan de beroemde kunstmatige intelligentie, zelfs als
deze laatste heeft scherpere klauwen.
Hoe kunnen we niet citeren die Amerikaanse ogres, de GAFAM (Google, Apple, Facebook, Amazon en Microsoft) of BATX, hun alter-ego's aan de andere kant van de Stille Oceaan (de Chinese reuzen: Baidu, Alibaba, Tencent en Xiaomi).
Hun metabolisme is gebaseerd op de collectie, met onze hulp, van de maximale hoeveelheid gegevens over onze kleinste handelingen en gebaren, onze dagelijkse activiteiten "verhogen" met een groot aantal mobiele apps en onderling verbonden voorwerpen die ons leven zouden moeten vergemakkelijken.

### Algoritmen die onze persoonlijke gegevens opeten

De resulterende algoritmen zijn polymorf.
Ze zijn gegroeid, ons observerend van veraf, bespioneren onze activiteiten online, en de plaatsen die we het meest frequent.
Zij dan boven onze interacties uitstijgt om beter te kunnen bepalen wie
autoriteit, zonder rekening te houden met de logica van het stemmen door de bevolking en classificaties op basis van verdienste.

Daarna, in een derde moment, gingen ze onze digitale intimiteit binnen, en analyseerden ze de kwaliteit en frequentie van onze uitwisselingen om onze reputatie te beoordelen en onze affiniteiten op te sporen.

Tot slot verbergen ze zich voor het oog om de kleinste van onze verlangens, om ze te kunnen vormgeven.

Aan één zijde*** | **Above*** | **Within** | **Beneden*** |
| --- | --- | --- | ---| --- |
**Example*** | Audience measurement, Google Analytics, reclametabbladen | Google PageRank, Digg, Wikipedia | Aantal vrienden op Facebook, Retweets op Twitter, notities en opinies | Aanbevelingen over Amazon, behaviour based advertising |
**Data** | Bezoeken | Relaties | Likes | Tracking |
Populatie*** | Representatieve steekproeven | Stemmentelling, gemeenschappen | Sociale netwerken, affiniteiten, declaratief | Impliciete individuele gedragingen |
Berekeningstype*** | Vote | Classificatie naar verdienste | Benchmark | Machineeducatie |
Principe*** | Populariteit | Autoriteit | Reputatie | Voorspelling | Populariteit

Volgens Domenique Cardon in "À quoi rêvent les algorithmes".* [^4].

Deze verschillende generaties algoritmen leven nog steeds naast elkaar, en zijn goed herkenbaar in die zin dat ze ons zeer efficiënt voorzien van veel diensten.
Ze proberen ons ons "digitaal dividend" [^5] te laten betalen omdat ze ons bestaan discreet in te delen en in de fijnst mogelijke plakjes te snijden, in volgorde van om alle monetiseerbare informatie te extraheren [^6].

Elke staat fokt een angstaanjagende oger die werkt in de surveillance.
De belangen van deze ogre vaak mengen met die van haar vrienden de commerciële ogres, als het schaamteloos hun winkels overvalt, met hun goedkeuring [^7].
Zijn onverzadigbare eetlust leidt het tot stalken die plaatsen met de meeste dataverkeer.
Aangenomen wordt dat het in een hooiberg een terrorist moet kunnen vinden, hoewel het vaak lijdt aan bijziendheid en obesitas, blijken efficiënter bij het stelen van politieke en industriële geheimen dan bij het vangen van de slechteriken voor zij actie ondernemen.

### Algoritmen die openbare gegevens eten

De verschillende bestuurslagen van de ordestrijdkrachten cultiveren ook bloeiende tuinen met veel geparfumeerde gegevens: biometrische, fiscale, milieugegevens,
stedelijk, professioneel of zelfs verband houdend met de gezondheid.

Blijkbaar neutraal en objectief, de openbare algoritmische wezens zou de oplossing zijn voor de verschillen in behandeling ten opzichte van de arbitrages tegen sommige ambtenaren.
Toch kunnen ze heel worden families in kafkaiaanse insecten die in de film aan de typemachine hangen Brazilië* [^8].
In feite zijn zij het die bepalen welke school ons kind moet gaan naar, of u sociale subsidies kunt krijgen, welke banen u kunt vinden aanvragen en als uw menstruatiecyclus rijp is om zich voort te planten.  
De handelaars in persoonsgegevens bieden vriendelijk aan om overheidsinstanties te helpen bij de digitalisering en kloon de mooiste planten in de openbare tuin, zij het culturele bloemen of geneeskrachtige kruiden.
Net als de handelaren, de krachten van de orde passeren van waarnemingen met betrekking tot voorspellingen, en niet alleen om de inzameling van afval te optimaliseren, maar ook om de politiediensten ook te sturen naar plaatsen waar de kans op een misdrijf het grootst is worden geëngageerd dankzij hun algohonden, PredPol CompStat of HunchLab [^9].

### Algoritmen die geld eten

Thomas Peterffy is een geldschieter die zich wijdde aan het vervangen van de makelaars en hun manuele handelingen met geautomatiseerde machines.
In 1987, bij het zien van dat het aantal bestellingen geplaatst door Peterffy was verrassend hoog, de verantwoordelijken van de markten stuurde een inspecteur, die, waar hij verwachtte te vinden een kamer gevuld met blanke mannen schreeuwen en zweten, gevonden niets meer dan een IBM-computer zijn aangesloten op een Nasdaq-terminal [^10] met een schroeifunctie.
Zo was dat in 1987, algoritmen werden op de financiële markten geïntroduceerd.

Vandaag de dag, algo-trading is overal, en de serene, algoritmische knipperen van de informatienetwerken is in de plaats gekomen van de hysterische handelaren.
Echter, zelfs deze digitale financiële wezens zich hebben toegestaan om ingehaald door hoogfrequente algo-handelaars, die met de lichtsnelheid bewegen.
Ze bouwen routes om sneller tot de verkoop te komen dan de anderen [^11], waardoor winst bij elke operatie.
Op dit moment vinden ze hun toevlucht in de vele "duisternis pools" die de banken hebben kunnen vormen dankzij het paradoxale versoepeling van de regelgeving.
In het lucratieve comfort dat soms gezien wordt in de "Flitscrashes" [^12], neemt de diversiteit aan algoritmische soorten toe (Blast,
Sluipen, Sniffer, Iceberg, Haai, Sumo,... [^13]) op één lijn met de complexiteit van hun strategieën, waardoor de "markten" steeds onleesbaarder worden en oncontroleerbaar, ook al wordt ervan uitgegaan dat zij worden gereguleerd door de Strook van onzichtbare handen.

### Algoritmen die menselijke hersenen eten

De eindfamilie die in ons bestiarium van algoritmen geïdentificeerd moet worden, zijn de volgende wiens wil is het menselijk brein te vullen, en degenen die, integendeel,
streven er uiteindelijk naar deze te vervangen.
Kunstmatige intelligenties moeten worden gevoed met gegevens om mensen in een breed scala van processen te kunnen vervangen.
Dit is iets wat Google doet met zijn reCAPTCHA [^24] project, die onleesbaar zijn
afbeeldingen die we moeten ontcijferen en transcriberen om de server te laten zien dat we zijn geen robots, maar mensen, die de Turing test in omgekeerde richting doorstaan [^25].
De grote innovatie van reCAPTCHA is dat het resultaat van uw antwoorden rechtstreeks om kunstmatige intelligentie en de evolutie van Google te voeden programma's: ontcijferen van tekst om de digitalisering van boeken te verbeteren, het identificeren van huisnummers om het in kaart brengen te verfijnen, en nu het identificeren van beelden met dieren of verkeersborden, om autostuurautomaten minder kortzichtig te maken.
De de gecumuleerde resultaten worden steeds relevanter en vertegenwoordigen miljoenen uren menselijke arbeid [^26].

In termen van het algoritme dat bijdraagt aan het voeden van onze hersenen, is dit, als het is vriend het verzamelen van persoonlijke gegevens, steeds uitgebreider en subtiel.
We voeden de hersenen dagelijks met behulp van een zoekmachine die ons laat zien waar vindt u de juiste plaats, de meest nauwkeurige informatie, de meest symboolvideo.
Begin 2017: in 92,8% van de gevallen waarin wordt gezocht naar motor was Google.
Dit maakt het tot een culturele dictator in een totaal nieuwe hegemonische positie (en wat doet de concurrentie?!).
Niet verschijnend binnen de eerste resultaten pagina's is als niet bestaand.
Toch is de Google-zoekopdracht algoritme is een jaloers bewaakt industrieel geheim en kan alleen worden tegengegaan rechts om vergeten te worden [^27].

Uit de surrealistische ervaring van de onderzoekers in het laboratorium dat is
Facebook [^28], die experimenten uitvoerde in 2010 op 61 miljoen gebruikers, tijdens de Amerikaanse congresverkiezingen, is het bekend dat het beheersen van de politieke berichten hebben een directe invloed op de mensen die onbewuste cavia's worden gemaakt varkens, alsmede die van hun vrienden en vrienden van vrienden.

Van valse nieuwsberichten die de waarheid hebben verpletterd op de sociale netwerken, uiteindelijk zwellen de gelederen van de post-truth.
Welke politieke lijn volgt de algoritmen die de inhoud van onze "muren" bepalen?
Oplossingen integreren problemen in verband met het aanzetten tot haat en intimidatie ook op deze platforms zullen de algoritmen en hun controllers snel in de officiële de positie om de moraal van een groot deel van de samenleving te beheersen.

One might think that to faster reach the point of technological singularity [^29], our digital creatures are crouching in the shadows and plot to make us servile.

Algorithmic governance [^30] would be a new mode of governing behaviour, fruit of shifts in our relationship with the other, with the group, with the world, with the very sense of the things that have, thanks to or despite the digital turn, fundamental repercussions on the way norms are created, and with them, obedience [^31].

When an algorithm eats from the human brain, this can also lead to the clinical death of the human in question.
This can be said of the algorithms that predefine the victims of killer drones, even if they are piloted by men and women.
How do the algorithms of a driverless car chose the lesser evil/or number of deaths, when they are involved in an accident that cannot be avoided?
Cyber war flies low over our occupied networks, each country sharpening its algorithms to be more and more insidiously lethal than the enemy.

## How do we know if an algorithm is bad or good?

Is a bad algorithm one which turns video surveillance cameras into an army of blood-thirsty botnets that come down in droves to strangle the servers?
Is a good algorithm one which reminds me of my friends' birthdays?
Setting the criteria is not so simple, because we have to consider interdependence between algorithms, the data they use and the intentions behind them.
Nevertheless, it can be hoped that a good algorithm will comply with the following:

- it should be “auditable” and therefore consist of open and documented source code;
- it should be “open” and therefore only feed on sets of “open data”, that are complete and “harvestable” by others, which means access should be discriminated and should be paid for certain commercial uses;
- it should be “loyal and fair” without the capacity to create discrimination or injustice (social [^32], gender-based [^33], etc.)  nor to damage human beings [^34];
- it should be “transparent” [^35] and capable of conducting systematic audits of its own operations and evolution (if it has learning or predictive capabilities) and be capable of subjecting itself to citizen's control;
- it should be “modifiable” and ready to respond to complaints that could require changes to the function of the algorithm.

In deze zoektocht naar algoritmische moraliteit is het ook noodzakelijk om de "poorten", de API's (die staan voor "Application Public Interfaces") die het mogelijk maken deze digitale wezens om gegevens van andere servers en diensten op te zoeken, of om containers plaatsen of aas leggen... deze API's kunnen worden beschouwd als door een octrooi beschermd voor de industrie: een nieuwe vorm van octrooiering van anti-open-sourcesoftware.
Deze havens kan worden geopend of gesloten naar strategisch oordeel van de eigenaar, of tolgelden kunnen ten uitvoer worden gelegd wanneer er veel verkeer van een algoritme is, indien dat het geval is monetarisering wordt opportuun.

In de publieke sfeer en het maatschappelijk middenveld kunnen we ons voorstellen dat het bovenstaande genoemde criteria van openheid, transparantie, verantwoordingsplicht en aanpasbaarheid zou op een dag gerespecteerd kunnen worden.
Dit is moeilijker voor te stellen in het lucratieve, privésfeer, waar gegevens en de algoritmen die deze verbruiken, worden verwerkt beschouwd als "de olie van de toekomst" [^36].

Zo een groep Amerikaanse onderzoekers en enkele "reuzen" van de digitale wereld hebben geprobeerd de "principes voor verantwoordelijke algoritmen" [^37] te formuleren en zij zijn bijeengekomen om een ontmoeting aan te gaan over de ethiek van het artificiële intelligentie [^38].
Dit is een goede manier om tegen politici en betrokkenen te zeggen burgers dat de private sector hierop kan "anticiperen en administreren".
complexiteit met positieve resultaten, dus er is echt geen behoefte aan wetgeving.

Het gaat er echter niet om transparantie te eisen voor de code van het algoritmen, maar eerder voor hun doelen.
Aangezien deze niet beperkt zijn tot commerciële communicatie, is het noodzakelijk om de wet in te zetten als dwangmiddel [^39].
We kunnen ons troosten in het participatieve debat dat in Frankrijk plaatsvindt over het "recht van de digitale republiek" dat heeft geleid tot de verplichting om transparantie met betrekking tot alle algoritmen die gebruikt worden door de orderkrachten [^40], of zelfs het "TransAlgo"-initiatief van INRIA [^41], dat de volgende aspecten wil beoordelen verantwoordingsplicht en transparantie van informatierobots.

## soevereine algoritmische futurutopieën

Dus, hoe gaan we van een algoritmisch beest dat we moeten lijden aan een huisdier dat we veevoer?
Laten we een paar regenwormen composteren om de biotechnologische vertakkingen die mannen en technologie ertoe aanzetten in siliciumharmonie te leven.
Hoe kunnen we ons lot weer in eigen handen nemen, onze mentale autonomie heroveren, onze technologische soevereiniteit, die vandaag de dag wordt gedreven door algoritmen in de ruimte van sociale controle.

Code is een politieke doelstelling, zoals in deze "numerieke" wereld gevuld met algo-bots die onze realiteit binnendringen.
Als politieke objecten kunnen we daarom aanval met de klassieke wapens: militantie, lobby en bewustmaking politieke macht, pogingen om de regelgeving te beïnvloeden en te verdiepen processen en het waarderen van initiatieven die bijdragen aan autonomie en geluk voor mensen.
Even belangrijk is het om een belangrijkere rol te eisen voor het maatschappelijk middenveld bij de regulering van en normen voor het internet, en de goedkeuring van normen voor netwerktechnologie [^42], waarbij het equivalent wordt genomen van een artikel van de grondwet van een land als voorbeeld.

Op individueel niveau is het zonder enige twijfel noodzakelijk om het "dogliseren" van de Internet [^43].
Dit betekent, zoals de vereniging Framasoft voorstelt, dat zij steun zal verlenen aan het onderbrengen van autonome, transparante, open, neutrale en op solidariteit gebaseerde diensten (zie bijvoorbeeld het KITTENS initiatief [^44]), of self-hosting [^45] in een onambitieuze miniserver.
Het is ook mogelijk om jezelf te camoufleren met end-to-endencryptie, hoewel deze niet altijd aanpasbaar en ook niet mogelijk is aan adopteren (PGP en e-mails); en afhankelijk van de situatie kunnen er resources zijn om interferentie te creëren, in een poging om de "echte" gegevens te verbergen binnen fictieve maar geloofwaardige gegevens, die een vriendelijk algoritme in overvloed kan leveren.

Vanuit het oogpunt van de publieke macht is er werk aan de winkel, de weg naar ethische transparantie is open, zij hoeft alleen maar stevig onder druk te worden gezet.
Van natuurlijk heb je tegenwoordig een vreemd kapsel en make-up [^46] nodig om te ontsnappen aan de gezichtsherkenningssystemen [^47].
Biometrische bestanden en de koppeling van openbare gegevens databanken en de digitale afgeleide instrumenten van de noodtoestand, die nu permanent, nodig ons uit om niet al onze bytes in een mand.

Het is ook mogelijk om deel te nemen aan het voederen van afval aan deze "algo-AI", gewoon zoals de Twitter-gebruikers die erin geslaagd om Microsoft's AI TAY seksistische, racistische en pro-Hitler in minder dan een dag [^48].

We could imagine instead raising little “algo-ponies” that would exclaim, with a wave of their multi-coloured manes, against a background of green fields of data, that “friendship is magic!”.

Kaaszucht buiten beschouwing gelaten, is het misschien nodig om een digitale tussenpersoon voor te stellen, een "proxy" tussen ons, onze gegevens en de publieke en private actoren die hen ontvangen.
Deze tussenpersoon zou Eliza [^49], mijn strikt persoonlijke AI, gemakkelijk kunnen hosten.
die zich voedt met mijn activiteiten en voorkeuren om mij te helpen gegevens beter te delen en inhoud, anoniem, waarbij deze als algemene informatie aan overheidsinstanties worden verstrekt interesseren, versleutelen of verbergen om te ontsnappen met mijn vrienden die niet erin slagen om uit de commerciële sociale netwerken.
Uitgedeeld in ieders portemonnee, persoonlijke AI's zouden symbiotisch kunnen worden, in overeenstemming met hun docenten, om de mensheid microficties te vertellen op politiek en cultureel gebied context, met het oog op het bouwen van harmonieuze realiteiten waar algoritmen,
De mens, de natuur en de anorganische wereld kunnen vreedzaam samenleven.

[^1] Deze titel verwijst naar het boek van Cathy O'Neil: Wapens van wiskunde
    Vernietiging: Hoe Big Data de ongelijkheid en bedreigingen vergroot
    Democratie*. Kroon, 2016.

[^2] In deze futuristische roman van Isaac Asimov hebben de Verenigde Staten zich geconverteerd naar een "elektronische democratie", waarbij de computer Multivac één enkele code selecteert persoon om een aantal vragen te beantwoorden. Multivac zal dan de antwoorden en andere gegevens om te bepalen wat de uitslag van een verkiezing zou zijn zijn, waarbij moet worden voorkomen dat er daadwerkelijk verkiezingen moeten worden gehouden gehouden. https://en.wikipedia.org/wiki/Franchise_%28short_story%29

[^3] https://fr.wikipedia.org/wiki/Bestiaire

[^4] Dominique Cardon: Een quoi rêvent les algoritmes. Nos vies à l'heure: Nrs.  vies à l'heure des big data*. Le Seuil, 2015.

[^5] Evgenij Morozov en Paas: *Le mirage numérique: Gieten une politique du Big Data*. Les Prairies Ordinaires, 2015.

[^6] http://centenaire-shannon.cnrs.fr/chapter/la-theorie-de-information

[^7] https://fr.wikipedia.org/wiki/PRISM_%28programme_de_surveillance%29

[^8] Terry Gilliam: Brazilië (1985). http://www.imdb.com/title/tt0088846/

[^9] Cathy O'Neil: Wapens van de dood vernietiging: Hoe groot de gegevensverhogingen Ongelijkheid en bedreiging van de democratie*. Kroon, 2016.

[^10] Enkele dagen later bepaalde hij dat de bestellingen van de toetsenbord van de terminal en gaf Peterfly een week om af te sluiten van
    IBM. In die tijd nam Peterffy ingenieurs in dienst om een camera-oog te bouwen om het scherm te lezen en de informatie naar de IBM hersenen te sturen waar elektromagnetische handen konden nemen de orders en sturen ze naar de aansluiting via het toetsenbord.

[^11] Sluipschutter in Mahwah: Antropologie, marktstructuur & de aard van
    beurzen. https://sniperinmahwah.wordpress.com/

[^12] SDe Flash Crash van 6 mei 2010 geanalyseerd door Nanex: http://www.nanex.net/20100506/FlashCrashAnalysis_Intro.html en https://www.youtube.com/watch?v=E1xqSZy9_4I

[^13] Laumonier Alexandre: *5/6*. Zones Sensibles edities, 2014. 
    http://www.zonessensibles.org/livres/6-5/ 
 
[^14] https://www.washingtonpost.com/news/worldviews/wp/2013/04/23/syrian-hackersclaim-ap-hack-that-tipped-stock-market-by-136-billion-is-it-terrorism/ 
 
[^15] Dit schepsel is zo duur (een enkele handeling vereist zo veel elektriciteit als een gemiddeld Amerikaans huis verbruikt in anderhalve dag), dat het is voornamelijk in China gevestigd en verloopt momenteel zeer traag.  http://motherboard.vice.com/read/bitcoin-is-unsustainable 
 
[^16] https://marmelab.com/blog/2016/04/28/blockchain-for-web-developers-thetheory.html 
 
[^17] Kapitalisatie en dagelijkse bewegingen van crypto-valuta's: http://coinmarketcap.com/ 
 
[^18] https://www.ethereum.org/ 
 
[^19] https://en.wikipedia.org/wiki/The_DAO_%28organization%29 
 
[^20] Primavera De Filippi: "Ethereum: Freenet of Skynet?". Berkman Center, 2014. https://cyber.harvard.edu/events/luncheon/2014/04/difilippi 
 
[^21] http://www.theverge.com/2016/12/30/14128870/foxconn-robots-automation-appleiphone-china-manufacturing 
 
[^22] https://www.washingtonpost.com/news/innovations/wp/2016/05/16/meet-ross-thenewly-hired-legal-robot/ 
 
[^23] Bernard Stiegler: La Société automatique. L'avenir du travail.* Fayard, 2015. 
http://www.philomag.com/les-livres/fiche-de-lecture/la-societe-automatique-1lavenir-du-travail-11454 
 
[^24] https://www.google.com/recaptcha/intro/index.html 

[^25] https://en.wikipedia.org/wiki/Turing_test

[^26] http://www.bizjournals.com/boston/blog/techflash/2015/01/massachusettswomans-lawsuit-accuses-google-of.html

[^27] https://www.google.com/webmasters/tools/legal-removal-request?complaint_type=rtbf

[^28] A 61-million-person experiment in social influence and political mobilization: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3834737/

[^29] https://fr.wikipedia.org/wiki/Singularit%C3%A9_technologique

[^30] Antoinette Rouvroy and Thomas Berns: “Gouvernementalité algorithmique et perspectives d'émancipation: Le disparate comme condition d'individuation par la relation?”. Politics of algorithms.  Web-metrics.  *RESEAUX*, Vol.31, n.177, pp. 163-196 (2013). http://works.bepress.com/antoinette_rouvroy/47/

[^31] ifapa.me is a collective dedicated to research and subvert the effects of mathematization and quantification of daily life in necrocapitalist societies: http://www.ifapa.me/

[^32] https://www.washingtonpost.com/opinions/big-data-may-be-reinforcing-racialbias-in-the-criminal-justice-system/2017/02/10/d63de518-ee3a-11e6-9973c5efb7ccfb0d_story.html?utm_term=.b7f5ab5df1f9

[^33] http://www.genderit.org/feminist-talk/algorithmic-discrimination-andfeminist-politics

[^34] https://fr.wikipedia.org/wiki/Trois_lois_de_la_robotique

[^35] http://internetactu.blog.lemonde.fr/2017/01/21/peut-on-armer-la-transparencede-linformation/

[^36] Documentary “Le secret des 7 soeurs”: http://secretdes7soeurs.blogspot.fr/

[^37] http://www.fatml.org/resources/principles-for-accountable-algorithms

[^38] http://www.lemonde.fr/pixels/article/2016/09/28/intelligence-artificielleles-geants-du-web-lancent-un-partenariat-sur-l-ethique_5005123_4408996.html

[^39] http://www.internetactu.net/2016/03/16/algorithmes-et-responsabilites/

[^40] https://www.service-public.fr/particuliers/actualites/A11502

[^41] https://www-direction.inria.fr/actualite/actualites-inria/transalgo

[^42] The Internet Engineering Task Force (IETF): http://www.ietf.org/

[^43] http://degooglisons-internet.org/

[^44] http://chatons.org/

[^45] http://yunohost.org/

[^46] https://cvdazzle.com/

[^47] http://www.lemonde.fr/pixels/article/2016/10/19/inquietudes-autour-de-lareconnaissance-faciale-aux-etats-unis_5016364_4408996.html

[^48] https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbotgets-a-crash-course-in-racism-from-twitter

[^49] http://elizagen.org
